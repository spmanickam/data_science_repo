{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDEMY_DEEP_LEARNING_A-Z_ANN_KIRILL_2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#OneHotEncoder-(using-get_dummies)\" data-toc-modified-id=\"OneHotEncoder-(using-get_dummies)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>OneHotEncoder (using get_dummies)</a></span></li><li><span><a href=\"#Split\" data-toc-modified-id=\"Split-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Split</a></span></li><li><span><a href=\"#StandardScaler-(do-this-after-splitting)\" data-toc-modified-id=\"StandardScaler-(do-this-after-splitting)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>StandardScaler (do this after splitting)</a></span></li><li><span><a href=\"#ANN\" data-toc-modified-id=\"ANN-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>ANN</a></span><ul class=\"toc-item\"><li><span><a href=\"#BUILD\" data-toc-modified-id=\"BUILD-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>BUILD</a></span><ul class=\"toc-item\"><li><span><a href=\"#Add-first-hidden-layer\" data-toc-modified-id=\"Add-first-hidden-layer-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Add first hidden layer</a></span></li><li><span><a href=\"#Add-second-hidden-layer\" data-toc-modified-id=\"Add-second-hidden-layer-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Add second hidden layer</a></span></li><li><span><a href=\"#Add-output-layer\" data-toc-modified-id=\"Add-output-layer-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Add output layer</a></span></li></ul></li><li><span><a href=\"#TRAIN/FIT\" data-toc-modified-id=\"TRAIN/FIT-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>TRAIN/FIT</a></span></li><li><span><a href=\"#PREDICT\" data-toc-modified-id=\"PREDICT-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>PREDICT</a></span><ul class=\"toc-item\"><li><span><a href=\"#Convert-prediction-probability-values-to-boolean\" data-toc-modified-id=\"Convert-prediction-probability-values-to-boolean-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Convert prediction probability values to boolean</a></span></li></ul></li><li><span><a href=\"#EVALUATE\" data-toc-modified-id=\"EVALUATE-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>EVALUATE</a></span></li></ul></li><li><span><a href=\"#K-FOLD-CROSS-VALIDATION\" data-toc-modified-id=\"K-FOLD-CROSS-VALIDATION-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>K-FOLD CROSS VALIDATION</a></span></li><li><span><a href=\"#Dropout-Regularization-(is-THE-solutiorn-for-overfitting-im-deep-learning)\" data-toc-modified-id=\"Dropout-Regularization-(is-THE-solutiorn-for-overfitting-im-deep-learning)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Dropout Regularization (is THE solutiorn for overfitting im deep learning)</a></span></li><li><span><a href=\"#PARAMETER-TUNING-(GRID-SEARCH)\" data-toc-modified-id=\"PARAMETER-TUNING-(GRID-SEARCH)-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>PARAMETER TUNING (GRID SEARCH)</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES \n",
    "#     1) THEANO\n",
    "#         -> open source numerical computations library\n",
    "#         -> efficient fast numerical computations; \n",
    "#         -> numpy syntax\n",
    "#         -> can run on CPUs & GPUs(more cores;higher floating point calculations per second)\n",
    "#     2) TENSORFLOW\n",
    "#     3) KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "'''\n",
    "!pip install tensorflow\n",
    "!pip install theano\n",
    "!pip install keras\n",
    "\n",
    "Collecting theano\n",
    "  Downloading https://files.pythonhosted.org/packages/4d/b1/d490d88ab47f01f367f413bd2e47d86acf92c84157c5172c23903798bd70/Theano-1.0.3.tar.gz (2.8MB)\n",
    "    100% |████████████████████████████████| 2.8MB 4.5MB/s eta 0:00:01    40% |████████████▉                   | 1.1MB 686kB/s eta 0:00:03    44% |██████████████▏                 | 1.2MB 3.2MB/s eta 0:00:01\n",
    "Requirement already satisfied: numpy>=1.9.1 in /anaconda3/lib/python3.6/site-packages (from theano) (1.15.2)\n",
    "Requirement already satisfied: scipy>=0.14 in /anaconda3/lib/python3.6/site-packages (from theano) (1.1.0)\n",
    "Requirement already satisfied: six>=1.9.0 in /anaconda3/lib/python3.6/site-packages (from theano) (1.11.0)\n",
    "Building wheels for collected packages: theano\n",
    "  Running setup.py bdist_wheel for theano ... done\n",
    "  Stored in directory: /Users/pinky/Library/Caches/pip/wheels/10/82/05/9ef5e43bfcf906b4810f85f91b09d6daf7ad213d30179defa9\n",
    "Successfully built theano\n",
    "tensorflow 1.10.0 has requirement numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.15.2 which is incompatible.\n",
    "Installing collected packages: theano\n",
    "Successfully installed theano-1.0.3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update all conda libararies\n",
    "#!conda update -y --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda update -y matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uninstall pip's version\n",
    "#!pip uninstall -y matplotlib\n",
    "\n",
    "# DOESN'T WORK: !conda install matplotlib\n",
    "# WORKS: !conda install -c conda-forge matplotlib=3.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HouseKeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load '../../src/scripts/housekeeping.py'\n",
    "#Housekeeping\\\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "#Image(filename='images/extracting_data_from_db_template.png', height=300, width=400)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = os.path.join(os.pardir, '..', 'data', 'raw') \n",
    "churnDF = pd.read_csv(os.path.join(raw_data_path, 'Churn_Modelling.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churnDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnDF.drop(axis='columns', columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churnDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  OneHotEncoder (using get_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnDF = pd.get_dummies(churnDF, columns=['Geography', 'Gender'], prefix=[\"Geography\", \"Gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1                 1   \n",
       "1               1        112542.58       0                 0   \n",
       "2               0        113931.57       1                 1   \n",
       "3               0         93826.63       0                 1   \n",
       "4               1         79084.10       0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                  0                0              1            0  \n",
       "1                  0                1              1            0  \n",
       "2                  0                0              1            0  \n",
       "3                  0                0              1            0  \n",
       "4                  0                1              1            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churnDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOESN'T WORK (beacuse you CANNOT use OneHotEncoder to encode a string column)\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# oneHotEncoder = OneHotEncoder(categorical_features=['Geography', 'Gender'])\n",
    "# chrunDF2 = oneHotEncoder.fit_transform(churnDF)\n",
    "# ValueError: could not convert string to float: 'France'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "CreditScore          10000 non-null int64\n",
      "Age                  10000 non-null int64\n",
      "Tenure               10000 non-null int64\n",
      "Balance              10000 non-null float64\n",
      "NumOfProducts        10000 non-null int64\n",
      "HasCrCard            10000 non-null int64\n",
      "IsActiveMember       10000 non-null int64\n",
      "EstimatedSalary      10000 non-null float64\n",
      "Exited               10000 non-null int64\n",
      "Geography_France     10000 non-null uint8\n",
      "Geography_Germany    10000 non-null uint8\n",
      "Geography_Spain      10000 non-null uint8\n",
      "Gender_Female        10000 non-null uint8\n",
      "Gender_Male          10000 non-null uint8\n",
      "dtypes: float64(2), int64(7), uint8(5)\n",
      "memory usage: 752.0 KB\n"
     ]
    }
   ],
   "source": [
    "churnDF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = churnDF.drop('Exited', axis='columns')\n",
    "y = churnDF.Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
       "9995               0         96270.64                 1                  0   \n",
       "9996               1        101699.77                 1                  0   \n",
       "9997               1         42085.58                 1                  0   \n",
       "9998               0         92888.52                 0                  1   \n",
       "9999               0         38190.78                 1                  0   \n",
       "\n",
       "      Geography_Spain  Gender_Female  Gender_Male  \n",
       "9995                0              0            1  \n",
       "9996                0              0            1  \n",
       "9997                0              1            0  \n",
       "9998                0              0            1  \n",
       "9999                0              1            0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          8000\n",
       "Age                  8000\n",
       "Tenure               8000\n",
       "Balance              8000\n",
       "NumOfProducts        8000\n",
       "HasCrCard            8000\n",
       "IsActiveMember       8000\n",
       "EstimatedSalary      8000\n",
       "Geography_France     8000\n",
       "Geography_Germany    8000\n",
       "Geography_Spain      8000\n",
       "Gender_Female        8000\n",
       "Gender_Male          8000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler (do this after splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "standardScaler = StandardScaler()\n",
    "X_train = standardScaler.fit_transform(X_train)\n",
    "X_test = standardScaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUILD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=13, units=7, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=7, init='uniform', activation='relu', input_dim=13))   # 13+1/2 = 7 layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=7, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=7, init='uniform', activation='relu')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid')) # use submax for mulitple label classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN/FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 5s 589us/step - loss: 0.4826 - acc: 0.7960\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 3s 328us/step - loss: 0.4282 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 3s 329us/step - loss: 0.4229 - acc: 0.8020\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 3s 323us/step - loss: 0.4186 - acc: 0.8237 1s - \n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 3s 366us/step - loss: 0.4166 - acc: 0.8271\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 3s 333us/step - loss: 0.4145 - acc: 0.8302\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 3s 338us/step - loss: 0.4130 - acc: 0.8299\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 3s 357us/step - loss: 0.4117 - acc: 0.8324\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 3s 341us/step - loss: 0.4108 - acc: 0.8345\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 3s 347us/step - loss: 0.4095 - acc: 0.8335\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 3s 354us/step - loss: 0.4097 - acc: 0.8326\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 3s 385us/step - loss: 0.4084 - acc: 0.8342\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 3s 346us/step - loss: 0.4084 - acc: 0.8342\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 3s 336us/step - loss: 0.4080 - acc: 0.8327\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 4s 444us/step - loss: 0.4066 - acc: 0.8340\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 3s 372us/step - loss: 0.4067 - acc: 0.8346\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 4s 464us/step - loss: 0.4063 - acc: 0.8344\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 4s 501us/step - loss: 0.4054 - acc: 0.8336\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 5s 576us/step - loss: 0.4055 - acc: 0.8365\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 5s 591us/step - loss: 0.4055 - acc: 0.8340\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 4s 560us/step - loss: 0.4048 - acc: 0.8349\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 5s 596us/step - loss: 0.4048 - acc: 0.8350\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 3s 380us/step - loss: 0.4041 - acc: 0.8346\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 3s 399us/step - loss: 0.4042 - acc: 0.8349\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 3s 340us/step - loss: 0.4033 - acc: 0.8340\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 3s 378us/step - loss: 0.4033 - acc: 0.8357\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 3s 356us/step - loss: 0.4030 - acc: 0.8341\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 3s 322us/step - loss: 0.4032 - acc: 0.8357\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 3s 335us/step - loss: 0.4029 - acc: 0.8347\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 3s 347us/step - loss: 0.4025 - acc: 0.8359\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 3s 327us/step - loss: 0.4026 - acc: 0.8342\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 2s 301us/step - loss: 0.4029 - acc: 0.8347\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 2s 306us/step - loss: 0.4024 - acc: 0.8340\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 3s 322us/step - loss: 0.4023 - acc: 0.8354\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 2s 308us/step - loss: 0.4027 - acc: 0.8370\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 2s 301us/step - loss: 0.4021 - acc: 0.8337\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 3s 316us/step - loss: 0.4014 - acc: 0.8357 0s - loss: 0.\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 2s 312us/step - loss: 0.4020 - acc: 0.8352\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 3s 385us/step - loss: 0.4017 - acc: 0.8331\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 3s 361us/step - loss: 0.4020 - acc: 0.8349\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 3s 384us/step - loss: 0.4017 - acc: 0.8355\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 5s 579us/step - loss: 0.4021 - acc: 0.8336\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 3s 338us/step - loss: 0.4016 - acc: 0.8359\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 3s 374us/step - loss: 0.4019 - acc: 0.8360\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 3s 372us/step - loss: 0.4012 - acc: 0.8356\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 3s 349us/step - loss: 0.4014 - acc: 0.8349\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 3s 379us/step - loss: 0.4013 - acc: 0.8359\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 3s 423us/step - loss: 0.4017 - acc: 0.8356\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 3s 348us/step - loss: 0.4014 - acc: 0.8346\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 3s 409us/step - loss: 0.4010 - acc: 0.8366\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 3s 362us/step - loss: 0.4011 - acc: 0.8351\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 4s 462us/step - loss: 0.4014 - acc: 0.8349\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 4s 554us/step - loss: 0.4013 - acc: 0.8350\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 3s 342us/step - loss: 0.4010 - acc: 0.8355\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 2s 312us/step - loss: 0.4011 - acc: 0.8356\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 2s 281us/step - loss: 0.4006 - acc: 0.8362\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 2s 309us/step - loss: 0.4010 - acc: 0.8350\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 3s 314us/step - loss: 0.4010 - acc: 0.8357\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 2s 286us/step - loss: 0.4005 - acc: 0.8359\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 2s 300us/step - loss: 0.4008 - acc: 0.8349\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 2s 297us/step - loss: 0.4008 - acc: 0.8359\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 3s 421us/step - loss: 0.4004 - acc: 0.8361\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 4s 495us/step - loss: 0.4011 - acc: 0.8344\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 5s 565us/step - loss: 0.4005 - acc: 0.8359\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 4s 562us/step - loss: 0.4001 - acc: 0.8359\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 4s 498us/step - loss: 0.4005 - acc: 0.8332\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 5s 633us/step - loss: 0.4007 - acc: 0.8359\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 5s 605us/step - loss: 0.4005 - acc: 0.8359\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 6s 748us/step - loss: 0.4010 - acc: 0.8352\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 5s 567us/step - loss: 0.4000 - acc: 0.8360\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 5s 570us/step - loss: 0.4005 - acc: 0.8345\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 7s 825us/step - loss: 0.4007 - acc: 0.8354\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 5s 600us/step - loss: 0.4002 - acc: 0.8351\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 5s 611us/step - loss: 0.4008 - acc: 0.8345\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 6s 743us/step - loss: 0.4001 - acc: 0.8334\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 4s 470us/step - loss: 0.4000 - acc: 0.8350\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 4s 539us/step - loss: 0.4005 - acc: 0.8342\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 5s 587us/step - loss: 0.4004 - acc: 0.8345\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 5s 599us/step - loss: 0.4003 - acc: 0.8357\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 5s 618us/step - loss: 0.4005 - acc: 0.8357\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 5s 604us/step - loss: 0.4004 - acc: 0.8334\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 4s 524us/step - loss: 0.4007 - acc: 0.8329\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 5s 639us/step - loss: 0.4000 - acc: 0.8369\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 4s 461us/step - loss: 0.4004 - acc: 0.8335\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 4s 449us/step - loss: 0.4002 - acc: 0.8357\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 4s 541us/step - loss: 0.3999 - acc: 0.8340\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 3s 401us/step - loss: 0.4005 - acc: 0.8331\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 3s 378us/step - loss: 0.3998 - acc: 0.8360\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 0.4003 - acc: 0.8337\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 4s 553us/step - loss: 0.4003 - acc: 0.8339\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 4s 524us/step - loss: 0.4001 - acc: 0.8362\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 5s 584us/step - loss: 0.4005 - acc: 0.8354\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 5s 591us/step - loss: 0.3999 - acc: 0.8361\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 4s 525us/step - loss: 0.4005 - acc: 0.8345\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 5s 599us/step - loss: 0.4002 - acc: 0.8357\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 5s 663us/step - loss: 0.4002 - acc: 0.8352\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 4s 511us/step - loss: 0.4003 - acc: 0.8357\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 4s 561us/step - loss: 0.4006 - acc: 0.8346\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 5s 599us/step - loss: 0.4001 - acc: 0.8360\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 6s 702us/step - loss: 0.4003 - acc: 0.8359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEpoch 1/100\\n8000/8000 [==============================] - 6s 782us/step - loss: 0.4832 - acc: 0.7957\\nEpoch 2/100\\n8000/8000 [==============================] - 4s 444us/step - loss: 0.4291 - acc: 0.7960\\nEpoch 3/100\\n8000/8000 [==============================] - 4s 519us/step - loss: 0.4209 - acc: 0.8131\\n...\\nEpoch 97/100\\n8000/8000 [==============================] - 4s 457us/step - loss: 0.3418 - acc: 0.8610 2s - loss: 0.343 - ETA:\\nEpoch 98/100\\n8000/8000 [==============================] - 3s 415us/step - loss: 0.3415 - acc: 0.8617\\nEpoch 99/100\\n8000/8000 [==============================] - 3s 405us/step - loss: 0.3408 - acc: 0.8602\\nEpoch 100/100\\n8000/8000 [==============================] - 3s 425us/step - loss: 0.3418 - acc: 0.8614\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size=10, nb_epoch=100)\n",
    "\n",
    "'''\n",
    "Epoch 1/100\n",
    "8000/8000 [==============================] - 6s 782us/step - loss: 0.4832 - acc: 0.7957\n",
    "Epoch 2/100\n",
    "8000/8000 [==============================] - 4s 444us/step - loss: 0.4291 - acc: 0.7960\n",
    "Epoch 3/100\n",
    "8000/8000 [==============================] - 4s 519us/step - loss: 0.4209 - acc: 0.8131\n",
    "...\n",
    "Epoch 97/100\n",
    "8000/8000 [==============================] - 4s 457us/step - loss: 0.3418 - acc: 0.8610 2s - loss: 0.343 - ETA:\n",
    "Epoch 98/100\n",
    "8000/8000 [==============================] - 3s 415us/step - loss: 0.3415 - acc: 0.8617\n",
    "Epoch 99/100\n",
    "8000/8000 [==============================] - 3s 405us/step - loss: 0.3408 - acc: 0.8602\n",
    "Epoch 100/100\n",
    "8000/8000 [==============================] - 3s 425us/step - loss: 0.3418 - acc: 0.8614\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1815121 ],\n",
       "       [0.35437876],\n",
       "       [0.16259202],\n",
       "       ...,\n",
       "       [0.1753319 ],\n",
       "       [0.17068844],\n",
       "       [0.11269962]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a38989748>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sort(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert prediction probability values to boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction > 0.5  # values greater than 0.5  is set to True, else, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9394    0\n",
       "898     1\n",
       "2398    0\n",
       "5906    0\n",
       "2343    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1545,   50],\n",
       "       [ 275,  130]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, prediction)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8375"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascore = accuracy_score(y_test, prediction)\n",
    "ascore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9394    False\n",
       "898      True\n",
       "2398    False\n",
       "5906    False\n",
       "2343    False\n",
       "Name: Exited, dtype: bool"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert y_test values to boolean\n",
    "y_test2 = y_test > 0\n",
    "y_test2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1545,   50],\n",
       "       [ 275,  130]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm2 = confusion_matrix(y_test2, prediction)\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8375"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascore2 = accuracy_score(y_test2, prediction)\n",
    "ascore2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
       "0               1        101348.88                 1                  0   \n",
       "1               1        112542.58                 0                  0   \n",
       "2               0        113931.57                 1                  0   \n",
       "3               0         93826.63                 1                  0   \n",
       "4               1         79084.10                 0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                0              1            0  \n",
       "1                1              1            0  \n",
       "2                0              1            0  \n",
       "3                0              1            0  \n",
       "4                1              1            0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16958176, -0.46460796,  0.00666099, -1.21571749,  0.8095029 ,\n",
       "         0.64259497, -1.03227043,  1.10643166, -1.01460667, -0.5698444 ,\n",
       "         1.74309049,  1.09168714, -1.09168714]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single_observation_array = np.array([[0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])   #create 2 dimensional array\n",
    "single_observation_array = np.array([[700, 40, 3, 60000.00, 2, 1, 1, 50000, 1,0,0, 1,0]])   #create 2 dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_observation_array_scaled = standardScaler.fit_transform(single_observation_array)\n",
    "single_observation_array_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_prediction = classifier.predict(single_observation_array_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3511116]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_prediction > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-FOLD CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    tempClassifier = Sequential()\n",
    "    tempClassifier.add(Dense(output_dim=7, init='uniform', activation='relu', input_dim=13))   # 13+1/2 = 7 layers\n",
    "    tempClassifier.add(Dense(output_dim=7, init='uniform', activation='relu')) \n",
    "    tempClassifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid')) # use submax for mulitple label classes\n",
    "    tempClassifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return tempClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn=build_classifier, batch_size=5, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ERROR:\n",
    "#accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, n_jobs=-1)\n",
    "#BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=13, units=7, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=7, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5333/5333 [==============================] - 10s 2ms/step - loss: 0.4783 - acc: 0.7984\n",
      "2667/2667 [==============================] - 1s 464us/step\n",
      "Epoch 1/1\n",
      "5333/5333 [==============================] - 8s 1ms/step - loss: 0.4726 - acc: 0.7934\n",
      "2667/2667 [==============================] - 1s 456us/step\n",
      "Epoch 1/1\n",
      "5334/5334 [==============================] - 8s 1ms/step - loss: 0.4700 - acc: 0.7964\n",
      "2666/2666 [==============================] - 1s 431us/step\n"
     ]
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train)\n",
    "'''Epoch 1/1\n",
    "5333/5333 [==============================] - 10s 2ms/step - loss: 0.4783 - acc: 0.7984\n",
    "2667/2667 [==============================] - 1s 464us/step\n",
    "Epoch 1/1\n",
    "5333/5333 [==============================] - 8s 1ms/step - loss: 0.4726 - acc: 0.7934\n",
    "2667/2667 [==============================] - 1s 456us/step\n",
    "Epoch 1/1\n",
    "5334/5334 [==============================] - 8s 1ms/step - loss: 0.4700 - acc: 0.7964\n",
    "2666/2666 [==============================] - 1s 431us/step\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81214849, 0.8008999 , 0.79519881])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802749066332165"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0070421346162269725"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()  # our variance is small;  overfitting DID NOT happen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout Regularization (is THE solutiorn for overfitting in deep learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "# Overfitting happens when there is a large difference in accuracies of training set v/s test set\n",
    "\n",
    "# Overfitting happens in K-fold cross validation, if the variance is high (this is because of difference in values of accuracies (some low values and some large values))\n",
    "\n",
    "#With Dropout, some random neurons are disabled for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def build_classifier1():\n",
    "    tempClassifier = Sequential()\n",
    "    tempClassifier.add(Dense(output_dim=7, init='uniform', activation='relu', input_dim=13))   # 13+1/2 = 7 layers\n",
    "    tempClassifier.add(Dropout(p=0.5))  #10% dropped\n",
    "    tempClassifier.add(Dense(output_dim=7, init='uniform', activation='relu')) \n",
    "    tempClassifier.add(Dropout(p=0.3))  #10% dropped\n",
    "    tempClassifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid')) # use submax for mulitple label classes\n",
    "    tempClassifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return tempClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=13, units=7, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=7, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5333/5333 [==============================] - 10s 2ms/step - loss: 0.4872 - acc: 0.7971\n",
      "2667/2667 [==============================] - 2s 656us/step\n",
      "Epoch 1/1\n",
      "5333/5333 [==============================] - 12s 2ms/step - loss: 0.4784 - acc: 0.7930\n",
      "2667/2667 [==============================] - 2s 734us/step\n",
      "Epoch 1/1\n",
      "5334/5334 [==============================] - 9s 2ms/step - loss: 0.4674 - acc: 0.7962\n",
      "2666/2666 [==============================] - 2s 706us/step\n"
     ]
    }
   ],
   "source": [
    "classifier1 = KerasClassifier(build_fn=build_classifier1, batch_size=5, nb_epoch=100)\n",
    "accuracies1 = cross_val_score(estimator=classifier, X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79190102, 0.8008999 , 0.79519881])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies1.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETER TUNING (GRID SEARCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def build_classifier_for_grid_search(p, optimizer):\n",
    "    tempClassifier = Sequential()\n",
    "    tempClassifier.add(Dense(output_dim=7, init='uniform', activation='relu', input_dim=13))   # 13+1/2 = 7 layers\n",
    "    tempClassifier.add(Dropout(p=p))  #10% dropped\n",
    "    tempClassifier.add(Dense(output_dim=7, init='uniform', activation='relu')) \n",
    "    tempClassifier.add(Dropout(p=p))  #10% dropped\n",
    "    tempClassifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid')) # use submax for mulitple label classes\n",
    "    tempClassifier.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return tempClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchClassifier = KerasClassifier(build_fn=build_classifier_for_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'batch_size': [25, 32],\n",
    "                'nb_epoch': [100, 200],\n",
    "                'optimizer':['adam', 'rmsprop'],\n",
    "                'p': [0.1, 0.2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch = GridSearchCV(estimator=gridSearchClassifier, param_grid=parameters, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=13, units=7, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=7, kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 6s 871us/step - loss: 0.5418 - acc: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 6s 785us/step - loss: 0.5576 - acc: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 6s 867us/step - loss: 0.5650 - acc: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 662us/step - loss: 0.5507 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 6s 814us/step - loss: 0.5469 - acc: 0.7925\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 741us/step - loss: 0.5499 - acc: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 754us/step - loss: 0.5425 - acc: 0.7968\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 725us/step - loss: 0.5587 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 761us/step - loss: 0.5690 - acc: 0.7943\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5517 - acc: 0.7946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 1ms/step - loss: 0.5624 - acc: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 929us/step - loss: 0.5833 - acc: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 915us/step - loss: 0.5815 - acc: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5557 - acc: 0.7968\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 1ms/step - loss: 0.5527 - acc: 0.7926\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 1ms/step - loss: 0.5765 - acc: 0.7929\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5601 - acc: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5346 - acc: 0.7963\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5582 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 961us/step - loss: 0.5615 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 943us/step - loss: 0.5666 - acc: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 980us/step - loss: 0.5556 - acc: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5764 - acc: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 954us/step - loss: 0.5664 - acc: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 971us/step - loss: 0.5673 - acc: 0.7935\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5747 - acc: 0.7926\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5627 - acc: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 1ms/step - loss: 0.5803 - acc: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 6s 830us/step - loss: 0.5672 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 941us/step - loss: 0.5930 - acc: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.6053 - acc: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5685 - acc: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 1ms/step - loss: 0.5669 - acc: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 905us/step - loss: 0.5888 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5661 - acc: 0.7932\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5525 - acc: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 997us/step - loss: 0.5916 - acc: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5835 - acc: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 906us/step - loss: 0.5905 - acc: 0.7943\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 959us/step - loss: 0.5583 - acc: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 1ms/step - loss: 0.5576 - acc: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5556 - acc: 0.7963\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 1ms/step - loss: 0.5494 - acc: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5602 - acc: 0.7965\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5530 - acc: 0.7918\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5537 - acc: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5809 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5541 - acc: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5719 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5455 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5461 - acc: 0.7968\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5516 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5506 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.6549 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5541 - acc: 0.7929\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5696 - acc: 0.7924\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5487 - acc: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5569 - acc: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.6566 - acc: 0.7938\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5653 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5477 - acc: 0.7965\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5516 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.6200 - acc: 0.7936\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5567 - acc: 0.7975\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5540 - acc: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5882 - acc: 0.7926\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5517 - acc: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5769 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5665 - acc: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5754 - acc: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5714 - acc: 0.7971\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5654 - acc: 0.7963\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5656 - acc: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5668 - acc: 0.7963\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5836 - acc: 0.7932\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5802 - acc: 0.7935\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 11s 2ms/step - loss: 0.5809 - acc: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 11s 1ms/step - loss: 0.5776 - acc: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5632 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 11s 1ms/step - loss: 0.5701 - acc: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5735 - acc: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5858 - acc: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5569 - acc: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5719 - acc: 0.7972\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5842 - acc: 0.7910\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.6077 - acc: 0.7911\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 14s 2ms/step - loss: 0.5685 - acc: 0.7972\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 12s 2ms/step - loss: 0.6104 - acc: 0.7931\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 11s 2ms/step - loss: 0.5652 - acc: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 12s 2ms/step - loss: 0.5720 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 15s 2ms/step - loss: 0.5781 - acc: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 14s 2ms/step - loss: 0.5627 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 0.5810 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 11s 2ms/step - loss: 0.5752 - acc: 0.7972\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.5680 - acc: 0.7936\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.5722 - acc: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 11s 2ms/step - loss: 0.6324 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 12s 2ms/step - loss: 0.5732 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 14s 2ms/step - loss: 0.5977 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 15s 2ms/step - loss: 0.5803 - acc: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 14s 2ms/step - loss: 0.6425 - acc: 0.7942\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 14s 2ms/step - loss: 0.5891 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 12s 2ms/step - loss: 0.5899 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 36s 5ms/step - loss: 0.5947 - acc: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.5800 - acc: 0.7929\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 22s 3ms/step - loss: 0.5957 - acc: 0.7935\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 22s 3ms/step - loss: 0.6038 - acc: 0.7965\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 30s 4ms/step - loss: 0.6248 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 25s 4ms/step - loss: 0.5811 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 15s 2ms/step - loss: 0.6069 - acc: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.6280 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.5907 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 59s 8ms/step - loss: 0.6032 - acc: 0.7940: 1s - loss: 0.6063 - acc: 0.7\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 72s 10ms/step - loss: 0.6058 - acc: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 30s 4ms/step - loss: 0.5887 - acc: 0.7932\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 12s 2ms/step - loss: 0.5924 - acc: 0.7942\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 11s 2ms/step - loss: 0.5928 - acc: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 11s 2ms/step - loss: 0.5994 - acc: 0.7942\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 12s 2ms/step - loss: 0.5813 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 12s 2ms/step - loss: 0.5914 - acc: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.5725 - acc: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 12s 2ms/step - loss: 0.5695 - acc: 0.7965\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 12s 2ms/step - loss: 0.5656 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 12s 2ms/step - loss: 0.5777 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.5766 - acc: 0.7922\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 12s 2ms/step - loss: 0.5896 - acc: 0.7932\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 12s 2ms/step - loss: 0.6074 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.5731 - acc: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.5821 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.5907 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.5702 - acc: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.5913 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.5715 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 14s 2ms/step - loss: 0.5770 - acc: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.5986 - acc: 0.7925\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 14s 2ms/step - loss: 0.6081 - acc: 0.7936\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.5947 - acc: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.5871 - acc: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 14s 2ms/step - loss: 0.5884 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 14s 2ms/step - loss: 0.6088 - acc: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 13s 2ms/step - loss: 0.6045 - acc: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 14s 2ms/step - loss: 0.5903 - acc: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 15s 2ms/step - loss: 0.5849 - acc: 0.7942\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 15s 2ms/step - loss: 0.5760 - acc: 0.7975\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 25s 3ms/step - loss: 0.5963 - acc: 0.7918\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.5937 - acc: 0.7936\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.5990 - acc: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 23s 3ms/step - loss: 0.5943 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.6239 - acc: 0.7943\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 14s 2ms/step - loss: 0.6340 - acc: 0.7942\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 15s 2ms/step - loss: 0.5836 - acc: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 15s 2ms/step - loss: 0.5917 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.6104 - acc: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 25s 3ms/step - loss: 0.6242 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.6038 - acc: 0.7922\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 15s 2ms/step - loss: 0.5896 - acc: 0.7942\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.5893 - acc: 0.7968\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.5807 - acc: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.5917 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.6121 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.5474 - acc: 0.7945\n"
     ]
    }
   ],
   "source": [
    "gridSearchModel = gridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestParameter = gridSearchModel.best_params_\n",
    "bestAccuracy = gridSearchModel.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 25, 'nb_epoch': 100, 'optimizer': 'adam', 'p': 0.1}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.796"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook UDEMY_DEEP_LEARNING_A-Z_ANN_KIRILL_2.ipynb to script\n",
      "[NbConvertApp] Writing 14329 bytes to UDEMY_DEEP_LEARNING_A-Z_ANN_KIRILL_2.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script UDEMY_DEEP_LEARNING_A-Z_ANN_KIRILL_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
