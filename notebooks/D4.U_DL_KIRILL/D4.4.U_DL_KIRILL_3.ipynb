{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
<<<<<<< HEAD
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Convolution\" data-toc-modified-id=\"Convolution-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Convolution</a></span></li><li><span><a href=\"#Pooling\" data-toc-modified-id=\"Pooling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Pooling</a></span></li><li><span><a href=\"#Flattening\" data-toc-modified-id=\"Flattening-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Flattening</a></span></li><li><span><a href=\"#Full-Connection\" data-toc-modified-id=\"Full-Connection-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Full Connection</a></span></li><li><span><a href=\"#Image-Processing\" data-toc-modified-id=\"Image-Processing-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Image Processing</a></span></li><li><span><a href=\"#TO-DO:-finish-the-lab\" data-toc-modified-id=\"TO-DO:-finish-the-lab-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>TO DO: finish the lab</a></span></li></ul></div>"
=======
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Convolution\" data-toc-modified-id=\"Convolution-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Convolution</a></span></li><li><span><a href=\"#Pooling\" data-toc-modified-id=\"Pooling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Pooling</a></span></li><li><span><a href=\"#Flattening\" data-toc-modified-id=\"Flattening-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Flattening</a></span></li><li><span><a href=\"#Full-Connection\" data-toc-modified-id=\"Full-Connection-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Full Connection</a></span></li><li><span><a href=\"#Image-Processing\" data-toc-modified-id=\"Image-Processing-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Image Processing</a></span></li><li><span><a href=\"#TO-DO-:-finish\" data-toc-modified-id=\"TO-DO-:-finish-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>TO DO : finish</a></span></li></ul></div>"
>>>>>>> 9a01db3f51dedadcaebdd63dd050043c7a6f2c13
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load '../../src/scripts/housekeeping.py'\n",
    "#Housekeeping\\\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "#Image(filename='images/extracting_data_from_db_template.png', height=300, width=400)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps:\n",
    "#     1) Convolution\n",
    "#     2) Max Pooling\n",
    "#     3) Flattening\n",
    "#     4) Full Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 32 feature detectors each with size 32 (this will result in 32 feature maps)\n",
    "clasifier.add(Convolution2D(32, 3,3, input_shape= (64, 64, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clasifier.add(Dense(output_dim=128, activation='relu'))\n",
    "clasifier.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "#clasifier.add(Dense(output_dim=1, activation='sigmoid'))\n",
    "clasifier.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: For binary outcome, use binary_crossentropy loss function; if you've more than 2 outcomes, use\n",
    "#categorical_crossentropy loss function\n",
    "clasifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "1686/8000 [=====>........................] - ETA: 4:43:17 - loss: 0.5612 - acc: 0.7039"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        '../../data/raw/Convolutional_Neural_Networks/dataset/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        '../../data/raw/Convolutional_Neural_Networks/dataset/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "clasifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=8000,\n",
    "        epochs=5,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mcats\u001b[m\u001b[m \u001b[34mdogs\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../data/raw/Convolutional_Neural_Networks/dataset/training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### TO DO: finish the lab"
=======
    "### TO DO : finish"
>>>>>>> 9a01db3f51dedadcaebdd63dd050043c7a6f2c13
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
